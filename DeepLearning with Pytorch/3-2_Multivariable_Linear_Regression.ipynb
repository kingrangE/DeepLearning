{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["jXL1M38axBnR"],"authorship_tag":"ABX9TyNtGRMOHPkcJ9lQIljnxWlZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 다중 선형 회귀 ( Multivariable_Linear_Regression )\n","- [3-1](https://colab.research.google.com/drive/1fLFUt0L3Ydm2G_wrP3F00E9jLpOvdxig)에서 진행한 linear regression은 x가 1개인 단순 선형 회귀 입니다.\n","- 3-2에서는 여러 개의 x로부터 y를 예측하는 다중 선형 회귀를 다룹니다.\n","  - 독립변수(y를 예측하기 위한 x)가 여러 개입니다."],"metadata":{"id":"A7uK_kAbq-ks"}},{"cell_type":"markdown","source":["## 변수를 3개 선언하여 실행"],"metadata":{"id":"jXL1M38axBnR"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mj5FBr7Lq49Q","executionInfo":{"status":"ok","timestamp":1739339034966,"user_tz":-540,"elapsed":10888,"user":{"displayName":"전길원","userId":"12549511235485585617"}},"outputId":"5c7256d3-592c-40be-c2d3-75c290b9f7b7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7faf0e7a6550>"]},"metadata":{},"execution_count":1}],"source":["# Implementing\n","## 1. setting\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","torch.manual_seed(42)"]},{"cell_type":"code","source":["## 2. variable\n","\n","X1_train = torch.Tensor([[1],[2],[3],[4],[5]])\n","X2_train = torch.Tensor([[10],[9],[8],[7],[6]])\n","X3_train = torch.Tensor([[13],[14],[11],[15],[12]])\n","\n","Y_train = torch.Tensor([[19],[14],[25],[32],[51]])"],"metadata":{"id":"uXf-zwtWsSEn","executionInfo":{"status":"ok","timestamp":1739339265665,"user_tz":-540,"elapsed":2,"user":{"displayName":"전길원","userId":"12549511235485585617"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["## 3. weight & bias\n","W1 = torch.zeros(1,requires_grad=True)\n","W2 = torch.zeros(1,requires_grad=True)\n","W3 = torch.zeros(1,requires_grad=True)\n","b = torch.zeros(1,requires_grad=True)"],"metadata":{"id":"wZ-KapBtsuWz","executionInfo":{"status":"ok","timestamp":1739339324312,"user_tz":-540,"elapsed":2,"user":{"displayName":"전길원","userId":"12549511235485585617"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["## 4. optimizer\n","opt = optim.SGD([W1,W2,W3,b],lr = 0.0001)"],"metadata":{"id":"Yq_iGejms83j","executionInfo":{"status":"ok","timestamp":1739340011308,"user_tz":-540,"elapsed":402,"user":{"displayName":"전길원","userId":"12549511235485585617"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["## 5. set epoch & train model\n","epochs = 1000\n","for epoch in range(1,epochs+1):\n","  output = X1_train*W1+X2_train*W2+X3_train*W3 + b\n","  loss = torch.mean((output-Y_train)**2)\n","  opt.zero_grad()\n","  loss.backward()\n","  opt.step()\n","  if epoch %100 == 0:\n","    print(f\"epoch {epoch}/{epochs} - loss : {loss.item()}, W1 : {W1.item()}\")\n","\n","#loss와 W1의 nan은 data scale의 문제입니다."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sm5QBvqLtFw0","executionInfo":{"status":"ok","timestamp":1739340331519,"user_tz":-540,"elapsed":1056,"user":{"displayName":"전길원","userId":"12549511235485585617"}},"outputId":"74a1eab2-5450-4eb6-9cac-b10778dc6560"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 100/1000 - loss : nan, W1.grad : nan\n","epoch 200/1000 - loss : nan, W1.grad : nan\n","epoch 300/1000 - loss : nan, W1.grad : nan\n","epoch 400/1000 - loss : nan, W1.grad : nan\n","epoch 500/1000 - loss : nan, W1.grad : nan\n","epoch 600/1000 - loss : nan, W1.grad : nan\n","epoch 700/1000 - loss : nan, W1.grad : nan\n","epoch 800/1000 - loss : nan, W1.grad : nan\n","epoch 900/1000 - loss : nan, W1.grad : nan\n","epoch 1000/1000 - loss : nan, W1.grad : nan\n"]}]},{"cell_type":"markdown","source":["## 변수를 행렬로 변환하여 실행\n","- 변수를 각각 3개 선언하는 경우 scale 문제가 발생합니다.\n","  - 1000개가 필요한 경우 1000개 선언 불가\n","- 따라서 벡터의 내적을 이용합니다.\n","  - 벡터의 내적으로 표현하기\n","    - H(x) = w1x1 + w2x2 + w3x3 + b 라면 아래와 같이 표현 가능합니다.\n","      - H(x) = [w1,w2,w3] * [x1,x2,x3]^T + [b1] (b는 내적 결과 행렬의 size를 따라갑니다. 3x1 * 1x3은 1x1이 결과이므로 b 또한 1x1 사이즈를 갖습니다.)"],"metadata":{"id":"WLY3Z9eVxECm"}},{"cell_type":"code","source":["# 1. setting -> Done (above)\n","# 2. variable\n","X_train = torch.Tensor([[1,2,3,4,5],\n","          [6,7,8,9,10],\n","          [11,12,13,14,15]]) # 3 x 5 행렬 선언\n","Y_train = torch.Tensor([[15],[40],[65]])"],"metadata":{"id":"Zm1MuMP1xjMf","executionInfo":{"status":"ok","timestamp":1739341475835,"user_tz":-540,"elapsed":417,"user":{"displayName":"전길원","userId":"12549511235485585617"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# 3. weight bias\n","W = torch.zeros((5,1),requires_grad=True)\n","b = torch.zeros(1,requires_grad=True)"],"metadata":{"id":"YTETlCbHyQsS","executionInfo":{"status":"ok","timestamp":1739342189690,"user_tz":-540,"elapsed":512,"user":{"displayName":"전길원","userId":"12549511235485585617"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# 4. optimizer\n","opt = optim.SGD([W,b],lr = 1e-5) # 1e-5 = 0.0001"],"metadata":{"id":"m7MbArUS0KmQ","executionInfo":{"status":"ok","timestamp":1739342191962,"user_tz":-540,"elapsed":452,"user":{"displayName":"전길원","userId":"12549511235485585617"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# 5. set epoch & train\n","epochs = 3000\n","for epoch in range(1,epochs+1):\n","  output = X_train.matmul(W).add(b)\n","  loss = torch.mean((Y_train.sub(output))**2)\n","  opt.zero_grad()\n","  loss.backward()\n","  opt.step()\n","  if epoch % 100 == 0 :\n","    print(f\"epoch {epoch}/{epochs} : loss {loss}\")\n","\n","#test를 위한 부분 test 시에는 grad 반영이 되면 안 되므로 no_grad 처리합니다.\n","with torch.no_grad() :\n","  new_input = torch.Tensor([[1,6,11,2,7]])\n","  pred = new_input.matmul(W)+b\n","  print(f\"예측 결과 : {pred}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RylhChdt01LG","executionInfo":{"status":"ok","timestamp":1739342194694,"user_tz":-540,"elapsed":1357,"user":{"displayName":"전길원","userId":"12549511235485585617"}},"outputId":"4654b92d-d8bc-4683-d940-a15cbf9ac7c2"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 100/3000 : loss 391.88623046875\n","epoch 200/3000 : loss 75.05513763427734\n","epoch 300/3000 : loss 14.52582836151123\n","epoch 400/3000 : loss 2.960533857345581\n","epoch 500/3000 : loss 0.7494533061981201\n","epoch 600/3000 : loss 0.32541635632514954\n","epoch 700/3000 : loss 0.24279622733592987\n","epoch 800/3000 : loss 0.22541563212871552\n","epoch 900/3000 : loss 0.22050638496875763\n","epoch 1000/3000 : loss 0.21799786388874054\n","epoch 1100/3000 : loss 0.21596068143844604\n","epoch 1200/3000 : loss 0.21402700245380402\n","epoch 1300/3000 : loss 0.2121267318725586\n","epoch 1400/3000 : loss 0.21024741232395172\n","epoch 1500/3000 : loss 0.20838655531406403\n","epoch 1600/3000 : loss 0.20654581487178802\n","epoch 1700/3000 : loss 0.20472244918346405\n","epoch 1800/3000 : loss 0.20291143655776978\n","epoch 1900/3000 : loss 0.20111145079135895\n","epoch 2000/3000 : loss 0.19933219254016876\n","epoch 2100/3000 : loss 0.19756917655467987\n","epoch 2200/3000 : loss 0.19581754505634308\n","epoch 2300/3000 : loss 0.19408388435840607\n","epoch 2400/3000 : loss 0.19236528873443604\n","epoch 2500/3000 : loss 0.190663143992424\n","epoch 2600/3000 : loss 0.18897807598114014\n","epoch 2700/3000 : loss 0.18730004131793976\n","epoch 2800/3000 : loss 0.18564695119857788\n","epoch 2900/3000 : loss 0.1840043067932129\n","epoch 3000/3000 : loss 0.18237276375293732\n","예측 결과 : tensor([[27.2626]])\n"]}]}]}