{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPmkKdN7U/VmY1dJQmxt22p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# MiniBatch & DataLoader\n","- Why have to use minibatch?\n","  - therefore, computation at a time takes a long time and requires a lot of computation.\n","\n","- 따라서 전체를 작은 배치 단위로 나누어 학습하는 개념이 등장하고 이것이 Minibatch입니다.\n","  - minibatch를 활용하면 1 epoch은 첫 번째 batch부터 마지막 batch까지 1회 학습한 것을 말합니다.\n","    - 1epoch은 전체 데이터가 한 번 전부 사용되는 것을 말하기 때문입니다.\n","  - minibatch의 숫자는 결국 minibatch의 크기가 결정하는데, 이 크기를 batchsize라고 합니다.\n","    - Batch sizes usually use a square of 2, because the memory of the CPU and GPU is 2 squares, so data transmission and reception are more efficient when it is 2 squares.\n","- iteration\n","  - 1 epoch에 필요한 minibatch 학습 횟수\n","    - 즉, iteration == minibatch의 개수 입니다.\n"],"metadata":{"id":"rzemlj_FKZT1"}},{"cell_type":"markdown","source":["## Minibatch를 위한 torch의 도구\n","### Dataset,DataLoader\n","- 이것을 통해 mini batch 학습, data shuffle, paralle까지 쉽게 수행 가능합니다.\n","- Dataset을 정의하고 정의한 것을 DataLoader에 전달\n"],"metadata":{"id":"yYSjOMwELvk5"}},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F2i5_3ReJ5rL","executionInfo":{"status":"ok","timestamp":1739349055183,"user_tz":-540,"elapsed":1,"user":{"displayName":"전길원","userId":"12549511235485585617"}},"outputId":"7d8130a2-5ccb-4801-e0f1-c8750cdb5bbf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7de411f92290>"]},"metadata":{},"execution_count":16}],"source":["## Tensor를 입력받아 Dataset 형태로 변환해주는 TensorDataset\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset,DataLoader\n","torch.manual_seed(42)"]},{"cell_type":"code","source":["## TensorDataset -> 기본적으로 input = tensor\n","x_train=torch.FloatTensor([[73, 80, 75],\n","                        [93, 88, 93],\n","                        [89, 91, 90],\n","                        [96, 98, 100],\n","                        [73, 66, 70]])\n","y_train=torch.FloatTensor([[152], [185], [180],[196],[142]])\n","dataset = TensorDataset(x_train,y_train)"],"metadata":{"id":"1ZAMSV9EN6r6","executionInfo":{"status":"ok","timestamp":1739349058403,"user_tz":-540,"elapsed":341,"user":{"displayName":"전길원","userId":"12549511235485585617"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["## Dataset을 만들면, DataLoader를 사용할 수 있습니다.\n","### DataLoader는 기본적으로 Dataset, batch_size 2개의 파라미터를 받습니다. (shuffle 도 자주 사용합니다.)\n","BATCH_SIZE = 2\n","loader = DataLoader(dataset,batch_size = BATCH_SIZE,shuffle=True)"],"metadata":{"id":"jpaawnybOTLX","executionInfo":{"status":"ok","timestamp":1739349060278,"user_tz":-540,"elapsed":539,"user":{"displayName":"전길원","userId":"12549511235485585617"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["## model과 optim을 제작합니다.\n","model = nn.Linear(3,1)\n","opt = optim.SGD(model.parameters(),lr=1e-5)"],"metadata":{"id":"CKgiDSiPOXfC","executionInfo":{"status":"ok","timestamp":1739349112190,"user_tz":-540,"elapsed":1,"user":{"displayName":"전길원","userId":"12549511235485585617"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["## train을 진행합니다.\n","epochs = 2000\n","for epoch in range(1,epochs+1):\n","  for batch_idx, samples in enumerate(loader):\n","    # print(batch_idx) # 진행 과정이 궁금하면 주석 해제 후 관찰\n","    # print(samples) # 진행 과정이 궁금하면 주석 해제 후 관찰\n","    x_train,y_train = samples\n","    output = model(x_train)\n","    loss = F.mse_loss(y_train,output)\n","    opt.zero_grad()\n","    loss.backward()\n","    opt.step()\n","\n","  if epoch % 100 == 0 :\n","    print(f\"epoch {epoch}/{epochs} : {loss:4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DpmtdPWLPlOl","executionInfo":{"status":"ok","timestamp":1739349118645,"user_tz":-540,"elapsed":4457,"user":{"displayName":"전길원","userId":"12549511235485585617"}},"outputId":"f6d33259-ecb7-4b7b-eb74-f2ba4ece36c8"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 100/2000 : 7.521517\n","epoch 200/2000 : 7.082115\n","epoch 300/2000 : 0.000069\n","epoch 400/2000 : 5.743284\n","epoch 500/2000 : 0.074526\n","epoch 600/2000 : 0.281449\n","epoch 700/2000 : 6.664364\n","epoch 800/2000 : 0.143212\n","epoch 900/2000 : 0.008201\n","epoch 1000/2000 : 3.569618\n","epoch 1100/2000 : 0.945022\n","epoch 1200/2000 : 0.161745\n","epoch 1300/2000 : 4.214658\n","epoch 1400/2000 : 0.256697\n","epoch 1500/2000 : 3.737546\n","epoch 1600/2000 : 4.778416\n","epoch 1700/2000 : 2.054229\n","epoch 1800/2000 : 1.269198\n","epoch 1900/2000 : 1.776869\n","epoch 2000/2000 : 1.137710\n"]}]},{"cell_type":"code","source":["## Custom Dataset\n","\"\"\"\n","Custom Dataset의 뼈대\n","\n","class MyData(Dataset):\n","  def __init__(self): # 데이터 전처리 부분\n","  def __len__(self): # 데이터셋의 길이를 가져오는 부분 (len(Dataset)에서 실행되는 부분입니다.)\n","  def __getitem__(self,idx): #데이터셋에서 특정 1개의 샘플을 가져오는 함수 (Dataset[i]에서 실행되는 부분입니다.)\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"lWdugFUwSc-I","executionInfo":{"status":"ok","timestamp":1739350709959,"user_tz":-540,"elapsed":2,"user":{"displayName":"전길원","userId":"12549511235485585617"}},"outputId":"b45c7667-ade0-417a-cd23-acd9b579230b"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nCustom Dataset의 뼈대\\n\\nclass MyData(Dataset):\\n  def __init__(self): # 데이터 전처리 부분\\n  def __len__(self): # 데이터셋의 길이를 가져오는 부분 (len(Dataset)에서 실행되는 부분입니다.)\\n  def __getitem__(self,idx): #데이터셋에서 특정 1개의 샘플을 가져오는 함수 (Dataset[i]에서 실행되는 부분입니다.)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["## Custom Dataset을 이용한 선형회귀\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset,DataLoader\n","class MyDataset(Dataset):\n","  def __init__(self):\n","      self.x_data = [[73, 80, 75],\n","              [93, 88, 93],\n","              [89, 91, 90],\n","              [96, 98, 100],\n","              [73, 66, 70]]\n","      self.y_data = [[152], [185], [180], [196], [142]]\n","  def __len__(self):\n","    return len(self.x_data)\n","  def __getitem__(self,idx):\n","    x = torch.FloatTensor(self.x_data[idx])\n","    y = torch.FloatTensor(self.y_data[idx])\n","    return x,y"],"metadata":{"id":"U5YsYC_HWxAX","executionInfo":{"status":"ok","timestamp":1739350809568,"user_tz":-540,"elapsed":335,"user":{"displayName":"전길원","userId":"12549511235485585617"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["dataset = MyDataset()\n","dataloader = DataLoader(dataset,batch_size=2,shuffle=True)\n","model = torch.nn.Linear(3,1)\n","optimizer = torch.optim.SGD(model.parameters(),lr=1e-5)"],"metadata":{"id":"IpO7bQs0YrKJ","executionInfo":{"status":"ok","timestamp":1739350873370,"user_tz":-540,"elapsed":385,"user":{"displayName":"전길원","userId":"12549511235485585617"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["epochs = 2000\n","for epoch in range(epochs):\n","  for batch_idx,sample in enumerate(dataloader):\n","    x_train,y_train = sample\n","    output = model(x_train)\n","    loss = F.mse_loss(y_train,output)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    if epoch % 100 == 0 :\n","      print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n","        epoch, epochs, batch_idx+1, len(dataloader),\n","        loss.item()\n","        ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"22nlmCAlZBP3","executionInfo":{"status":"ok","timestamp":1739351262398,"user_tz":-540,"elapsed":4153,"user":{"displayName":"전길원","userId":"12549511235485585617"}},"outputId":"f03920f3-f44f-41ed-95e0-8b365ae197c5"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/2000 Batch 1/3 Cost: 0.620303\n","Epoch    0/2000 Batch 2/3 Cost: 0.923488\n","Epoch    0/2000 Batch 3/3 Cost: 0.102913\n","Epoch  100/2000 Batch 1/3 Cost: 0.514346\n","Epoch  100/2000 Batch 2/3 Cost: 0.750052\n","Epoch  100/2000 Batch 3/3 Cost: 0.066901\n","Epoch  200/2000 Batch 1/3 Cost: 0.741161\n","Epoch  200/2000 Batch 2/3 Cost: 0.304402\n","Epoch  200/2000 Batch 3/3 Cost: 0.934136\n","Epoch  300/2000 Batch 1/3 Cost: 0.191779\n","Epoch  300/2000 Batch 2/3 Cost: 0.916370\n","Epoch  300/2000 Batch 3/3 Cost: 0.437480\n","Epoch  400/2000 Batch 1/3 Cost: 0.759907\n","Epoch  400/2000 Batch 2/3 Cost: 0.785733\n","Epoch  400/2000 Batch 3/3 Cost: 0.327191\n","Epoch  500/2000 Batch 1/3 Cost: 1.058382\n","Epoch  500/2000 Batch 2/3 Cost: 0.487384\n","Epoch  500/2000 Batch 3/3 Cost: 0.805354\n","Epoch  600/2000 Batch 1/3 Cost: 0.264247\n","Epoch  600/2000 Batch 2/3 Cost: 0.901120\n","Epoch  600/2000 Batch 3/3 Cost: 0.033232\n","Epoch  700/2000 Batch 1/3 Cost: 0.313617\n","Epoch  700/2000 Batch 2/3 Cost: 0.850789\n","Epoch  700/2000 Batch 3/3 Cost: 0.084397\n","Epoch  800/2000 Batch 1/3 Cost: 0.447670\n","Epoch  800/2000 Batch 2/3 Cost: 0.948828\n","Epoch  800/2000 Batch 3/3 Cost: 0.142048\n","Epoch  900/2000 Batch 1/3 Cost: 0.616891\n","Epoch  900/2000 Batch 2/3 Cost: 0.835630\n","Epoch  900/2000 Batch 3/3 Cost: 0.082187\n","Epoch 1000/2000 Batch 1/3 Cost: 0.087394\n","Epoch 1000/2000 Batch 2/3 Cost: 0.785875\n","Epoch 1000/2000 Batch 3/3 Cost: 1.279568\n","Epoch 1100/2000 Batch 1/3 Cost: 0.429474\n","Epoch 1100/2000 Batch 2/3 Cost: 0.342167\n","Epoch 1100/2000 Batch 3/3 Cost: 1.129717\n","Epoch 1200/2000 Batch 1/3 Cost: 0.821501\n","Epoch 1200/2000 Batch 2/3 Cost: 0.592440\n","Epoch 1200/2000 Batch 3/3 Cost: 0.083963\n","Epoch 1300/2000 Batch 1/3 Cost: 0.620044\n","Epoch 1300/2000 Batch 2/3 Cost: 0.086424\n","Epoch 1300/2000 Batch 3/3 Cost: 0.982469\n","Epoch 1400/2000 Batch 1/3 Cost: 0.166085\n","Epoch 1400/2000 Batch 2/3 Cost: 0.463528\n","Epoch 1400/2000 Batch 3/3 Cost: 1.165053\n","Epoch 1500/2000 Batch 1/3 Cost: 0.632742\n","Epoch 1500/2000 Batch 2/3 Cost: 0.655575\n","Epoch 1500/2000 Batch 3/3 Cost: 0.587725\n","Epoch 1600/2000 Batch 1/3 Cost: 0.321957\n","Epoch 1600/2000 Batch 2/3 Cost: 0.268089\n","Epoch 1600/2000 Batch 3/3 Cost: 1.571401\n","Epoch 1700/2000 Batch 1/3 Cost: 0.342850\n","Epoch 1700/2000 Batch 2/3 Cost: 0.295646\n","Epoch 1700/2000 Batch 3/3 Cost: 1.116167\n","Epoch 1800/2000 Batch 1/3 Cost: 0.632800\n","Epoch 1800/2000 Batch 2/3 Cost: 0.588789\n","Epoch 1800/2000 Batch 3/3 Cost: 0.127162\n","Epoch 1900/2000 Batch 1/3 Cost: 0.425889\n","Epoch 1900/2000 Batch 2/3 Cost: 0.319093\n","Epoch 1900/2000 Batch 3/3 Cost: 0.977001\n"]}]}]}